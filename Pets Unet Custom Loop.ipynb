{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of Dogs/Cats Dataset With Numpy\n",
    "\n",
    "### Gradient Checking: Stanford Course https://cs231n.github.io/neural-networks-3/\n",
    "\n",
    "To be safe it is best to use a short burn-in time during which the network is allowed to learn and perform the gradient check after the loss starts to go down.\n",
    "An incorrect initialization can slow down or even completely stall the learning process. Luckily, this issue can be diagnosed relatively easily. One way to do so is to plot activation/gradient histograms for all layers of the network. Intuitively, it is not a good sign to see any strange distributions - e.g. with tanh neurons we would like to see a distribution of neuron activations between the full range of [-1,1], instead of seeing all neurons outputting zero, or all neurons being completely saturated at either -1 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras import optimizers, models\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_image\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import itertools\n",
    "import timeit\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import imageio\n",
    "import PIL\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "mixed_precision.set_policy(policy)\n",
    "print(\"Compute dtype: %s\" % policy.compute_dtype)\n",
    "print(\"Variable dtype: %s\" % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"downloaded_datasets\\\\oxford_pets\\\\\"\n",
    "randomseed = 2019\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    print(\"Path\")\n",
    "    \n",
    "    ids_temp = next(os.walk(path + \"images\"))[2]\n",
    "    ids_1 = []\n",
    "    for i in ids_temp:\n",
    "        if i.endswith(\".jpg\"):\n",
    "            ids_1.append(i)\n",
    "            \n",
    "    random.seed(randomseed)\n",
    "    id_order = np.arange(len(ids_1))\n",
    "    np.random.shuffle(id_order)\n",
    "    \n",
    "    ids = []\n",
    "    \n",
    "    for i in range(len(id_order)):\n",
    "        ids.append(ids_1[np.int(id_order[i])])\n",
    "        \n",
    " \n",
    "    X = np.zeros((len(ids), img_height, img_width, 3), dtype=np.float32)\n",
    "    y = np.zeros((len(ids), img_height, img_width), dtype=np.float32)\n",
    "    print(\"Number of images: \" + str(len(ids)))\n",
    "    print(y.shape)\n",
    "    \n",
    "    if y.shape[0] == 0:\n",
    "        print(\"no image found\")\n",
    "        sys.exit()\n",
    "        \n",
    "    for n, id_ in enumerate(ids):\n",
    "        print(\"\\r Loading %s \\ %s \" % (n, len(ids)), end='')\n",
    "        \n",
    "        # load images\n",
    "        img = load_img(path + \"images\\\\\" + id_)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (img_height, img_width, 3), mode='constant', preserve_range = True)\n",
    "        \n",
    "        # load masks\n",
    "        id_mask = id_[:-4] + \".png\"\n",
    "        mask = img_to_array(load_img(path + \"annotations\\\\trimaps\\\\\" + id_mask, color_mode = \"grayscale\"))\n",
    "        mask = cv2.resize(mask, (img_height, img_width), interpolation = cv2.INTER_NEAREST)\n",
    "        # mask = resize(mask, (im_height, im_width, 3), mode='constant', preserve_range = True)\n",
    "        mask.astype(np.int)\n",
    "            \n",
    "        # save images\n",
    "        X[n, ...] = x_img.squeeze()\n",
    "        # y[n, ...] = mask.squeeze()\n",
    "        # print(mask.astype(int))\n",
    "        y[n] = mask.astype(int)\n",
    "        # to_categorical(mask.astype(int), 3)\n",
    "        # \n",
    "            \n",
    "    print(\"Done!\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_mask_channels(y_train, y_test):\n",
    "    y_train_reshaped = np.zeros((TRAIN_LENGTH, img_width, img_height), dtype=np.float32)\n",
    "    for idx, mask in enumerate(y_train):\n",
    "        y_train_reshaped[idx] = cv2.resize(mask, (img_width, img_height))\n",
    "\n",
    "    y_test_reshaped = np.zeros((TEST_LENGTH, img_width, img_height), dtype=np.float32)\n",
    "    for idx, mask in enumerate(y_test):\n",
    "        y_test_reshaped[idx] = cv2.resize(mask, (img_width, img_height))   \n",
    "\n",
    "\n",
    "    train_masks = np.zeros((TRAIN_LENGTH, img_width, img_height, 3), dtype=np.float32)\n",
    "    # train_images = X_train\n",
    "    for idx, mask in enumerate(y_train):\n",
    "        mask[mask < 1/255] = 0\n",
    "        mask.astype(np.int)\n",
    "        train_masks[idx] = to_categorical(mask, 3)\n",
    "        # train_masks[idx] = mask\n",
    "\n",
    "    test_masks = np.zeros((TEST_LENGTH, img_width, img_height, 3), dtype=np.float32)\n",
    "    # test_images = X_test\n",
    "    for idx, mask in enumerate(y_test):\n",
    "        mask[mask < 1/255] = 0\n",
    "        mask.astype(np.int)\n",
    "        test_masks[idx] = to_categorical(mask, 3)\n",
    "        # test_masks[idx] = mask\n",
    "    return train_masks, test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = get_data(path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(X_train)\n",
    "TEST_LENGTH = len(X_test)\n",
    "n_classes = 3\n",
    "\n",
    "y_train, y_test = expand_mask_channels(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X_train[0])\n",
    "plt.gca().axis(\"off\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(y_train[0])\n",
    "plt.gca().axis(\"off\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(X_test[0])\n",
    "plt.gca().axis(\"off\")\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(y_test[0])\n",
    "plt.gca().axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_height=img_height,  input_width=img_width, f_scale = 1):\n",
    "    \n",
    "    img_input = tf.keras.layers.Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    # -------------------------- Encoder --------------------------\n",
    "    \n",
    "    c1 = Conv2D(f_scale*16, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(img_input)\n",
    "    c1 = Conv2D(f_scale*16, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c1)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(f_scale*32, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(p1)\n",
    "    c2 = Conv2D(f_scale*32, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c2)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "    \n",
    "    c3 = Conv2D(f_scale*64, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(p2)\n",
    "    c3 = Conv2D(f_scale*64, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c3)\n",
    "    c3 = Conv2D(f_scale*64, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c3)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    \n",
    "    c4 = Conv2D(f_scale*128, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(p3)\n",
    "    c4 = Conv2D(f_scale*128, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c4)\n",
    "    c4 = Conv2D(f_scale*128, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c4)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "    \n",
    "    # ------------------------ Bottleneck -------------------------\n",
    "    \n",
    "    c5 = Conv2D(f_scale*256, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(p4)\n",
    "    c5 = Conv2D(f_scale*256, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c5)\n",
    "    c5 = Conv2D(f_scale*256, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c5)\n",
    "    c5 = Dropout(0.5)(c5)\n",
    "    \n",
    "    # -------------------------- Decoder --------------------------\n",
    "    \n",
    "    u6 = concatenate([UpSampling2D((2, 2))(c5), c4])\n",
    "    c6 = Conv2D(f_scale*128, 3, padding='same', kernel_initializer = 'he_normal')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation(\"relu\")(c6)\n",
    "    c6 = Conv2D(f_scale*128, 3, padding='same', kernel_initializer = 'he_normal')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation(\"relu\")(c6)\n",
    "    c6 = Conv2D(f_scale*128, 3, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation(\"relu\")(c6)\n",
    "\n",
    "    u7 = concatenate([UpSampling2D((2, 2))(c6), c3])\n",
    "    c7 = Conv2D(f_scale*64, 3, padding='same', kernel_initializer = 'he_normal')(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation(\"relu\")(c7)\n",
    "    c7 = Conv2D(f_scale*64, 3, padding='same', kernel_initializer = 'he_normal')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation(\"relu\")(c7)\n",
    "    c7 = Conv2D(f_scale*64, 3, padding='same', kernel_initializer = 'he_normal')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation(\"relu\")(c7)\n",
    "\n",
    "    u8 = concatenate([UpSampling2D((2, 2))(c7), c2])\n",
    "    c8 = Conv2D(f_scale*32, 3, padding='same', kernel_initializer = 'he_normal')(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation(\"relu\")(c8)\n",
    "    c8 = Conv2D(f_scale*32, 3, padding='same', kernel_initializer = 'he_normal')(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation(\"relu\")(c8)\n",
    "\n",
    "    u9 = concatenate([UpSampling2D((2, 2))(c8), c1]) # , axis=3\n",
    "    c9 = Conv2D(f_scale*16, 3, padding='same', kernel_initializer = 'he_normal')(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Activation(\"relu\")(c9)\n",
    "    c9 = Conv2D(f_scale*16, 3, padding='same', kernel_initializer = 'he_normal')(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Activation(\"relu\")(c9)\n",
    "    \n",
    "    logits = Conv2D(3, 1, padding='same', activation=\"relu\", kernel_initializer = 'he_normal')(c9)\n",
    "    \n",
    "    return tf.keras.Model(inputs=img_input, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    dice=0.0\n",
    "    smooth=1.0\n",
    "    for i in range(0, n_classes):\n",
    "        intersection = y_true[:,:,i] * y_pred[:,:,i] # \"area\" of overlap (for that class)\n",
    "        all = y_true[:,:,i] + y_pred[:,:,i] # total number of pixels combined (for that class)\n",
    "        intersection = K.sum(intersection, 1) # Add to \"intersection\" value along channel axis?\n",
    "        all = K.sum(all, 1) #  Add to \"total pixed number\" value along channel axis?\n",
    "        temp = (2. * intersection + smooth) / (all + smooth) # (2*area of overlap)/(total pixels combined)\n",
    "        temp = K.mean(temp) # ? get mean over batch ?\n",
    "        dice = dice + temp # add the dice score for each class\n",
    "    return dice/(n_classes) # divide the summed dice scores by number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to define a sample image and sample mask\n",
    "sample_image = X_train[11]\n",
    "sample_mask = y_train[11]\n",
    "\n",
    "def display(display_list):\n",
    "    '''display([sample_image, sample_mask])'''\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions():\n",
    "    display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(input_height=img_height,  input_width=img_width, f_scale = 0.5)\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau\n",
    "wait = 0 \n",
    "best_dice_coef = 0 \n",
    "patience = 5\n",
    "factor = 0.1\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "train_dice_coef = tf.keras.metrics.Mean(\"train_dice_coef\", dtype=tf.float32)\n",
    "valid_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "valid_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "valid_dice_coef = tf.keras.metrics.Mean(\"val_dice_coef\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x, y):\n",
    "    # Open a GradientTape to record the operations run during the forward pass\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True) \n",
    "        # +\n",
    "        # Regular precision\n",
    "        loss_value = loss_fn(y, logits)\n",
    "        # -\n",
    "        # +\n",
    "        # Mixed precision\n",
    "        # scaled_loss = opt.get_scaled_loss(loss_value)\n",
    "        # -\n",
    "        \n",
    "    # +\n",
    "    # Mixed precision\n",
    "    # scaled_gradients = tape.gradient(scaled_loss, model.trainable_weights)\n",
    "    # gradients = opt.get_unscaled_gradients(scaled_gradients)\n",
    "    # -\n",
    "    # +\n",
    "    # Regular precision\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    # -\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    # Update training metrics.\n",
    "    train_loss(loss_value)\n",
    "    train_accuracy(y, logits)\n",
    "    dice_score = dice_coef(y, logits)\n",
    "    train_dice_coef(dice_score)\n",
    "    return loss_value\n",
    "\n",
    "def test_step(model, x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_loss_value = loss_fn(y, val_logits)\n",
    "    valid_accuracy(y, val_logits) \n",
    "    valid_loss(val_loss_value)\n",
    "    dice_score = dice_coef(y, val_logits)\n",
    "    valid_dice_coef(dice_score)\n",
    "    return val_loss_value\n",
    "\n",
    "def progress(status, count, total, value=''):\n",
    "    bar_len = 50\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    print('\\r%s: [%s] %s / %s ... loss: %s' % *(status, bar, count, total, value), end='') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "num_steps = len(X_train) // BATCH_SIZE\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    # ------------------ TRAIN MODEL ON BATCHES ------------------\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(model, optimizer, x_batch_train, y_batch_train)\n",
    "        progress(\"training\", step, num_steps, round(float(loss_value)))\n",
    "    \n",
    "    # ------------------ VALIDATE MODEL ON BATCHES ------------------\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_loss_value = test_step(model, x_batch_val, y_batch_val)\n",
    "        progress(\"validation\", step, num_steps, round(float(val_loss_value)))\n",
    "    \n",
    "    wait += 1\n",
    "    if np.greater(float(valid_accuracy.result(), float(best_val_acc))):\n",
    "        print(\"\\nval_accuracy increased from %.4f to %.4f\" % (round(float(best_val_acc), 3), \n",
    "                                                              round(float(valid_accuracy.result()), 3)))\n",
    "        vest_val_acc = valid_accuracy.result()\n",
    "        wait = 0\n",
    "    elif total_wait >= early_stopping:\n",
    "        print(\"\\n val_accuracy did not increase: early stopping\")\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        train_dice_coef.reset_states()\n",
    "        valid_loss.reset_states()\n",
    "        valid_accuracy.reset_states()\n",
    "        valid_dice_coef.reset_states()\n",
    "        print(\"Time taken: %.2fs\" % (time.time() - epoch_start_time))\n",
    "        break\n",
    "    elif wait >= patience:\n",
    "        print(\"\\nval_accuracy did not increase: lowering learning rate\")\n",
    "        lr = float(K.get_value(optimizer.learning_rate))\n",
    "        new_lr = lr * factor\n",
    "        if new_lr <= 1e-10\n",
    "            print(\"Min learning rate reached: early stopping\")\n",
    "            break\n",
    "        K.set_value(optimizer.lr, new_lr)\n",
    "        wait = 0\n",
    "        print(\"Epoch %d: Learning rate is: %.10e\" % (epoch+1, new_lr))\n",
    "    else:\n",
    "        print(\"\\nval_accuracy did not increase\")\n",
    "        \n",
    "    template = \"Epoch {}: Loss: {} , Accuracy: {} , Dice: {} , Val Loss: {} , Val Accuracy: {} , Val Dice: {}\"\n",
    "    print(template.format(epoch+1,\n",
    "                         round(float(train_loss.result()), 2),\n",
    "                         round(float(train_accuracy.result()), 2),\n",
    "                         round(float(train_dice_coef.result()), 2),\n",
    "                         round(float(valid_loss.result()), 2),\n",
    "                         round(float(valid_accuracy.result()), 2),\n",
    "                         round(float(valid_dice_coef.result()), 2)))\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    valid_loss.reset_states()\n",
    "    train_dice_coef.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    valid_dice_coef.reset_states()\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - epoch_start_time))\n",
    "    \n",
    "    \n",
    "end_time = time.time()\n",
    "t_minutes = (end_time - start_time) // 60\n",
    "print(\"Training finished in %.1f minutes\" % t_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 25\n",
    "\n",
    "title = ['Input Image', 'Predicted Mask', 'True Mask']\n",
    "pred = model.predict(np.reshape(X_test[img_num], (1, img_width, img_height, 3)))\n",
    "pred = np.reshape(pred, (img_width, img_height, 3))\n",
    "pred = np.argmax(pred, axis=2)\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(title[0])\n",
    "plt.imshow(X_test[img_num])\n",
    "plt.gca().axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(title[2])\n",
    "plt.imshow(np.reshape(y_test[img_num], (img_width, img_height, 3)))\n",
    "plt.gca().axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(title[1])\n",
    "plt.imshow(pred)\n",
    "plt.gca().axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
