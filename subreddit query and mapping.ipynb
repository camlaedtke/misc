{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Reddit Data\n",
    "\n",
    "The notebook demonstrates how to extract massive amounts of reddit data in order to build a map of subreddits. \n",
    "\n",
    "Data extracted from https://files.pushshift.io/reddit/comments/\n",
    "- Files are around 2-10 times larger when uncompressed\n",
    "- Uncompressed files must be renamed to have .json file extension\n",
    "\n",
    "Code adapted from https://github.com/lmcinnes/subreddit_mapping\n",
    "\n",
    "Credit to reddit user /u/Stuck_In_the_Matrix and /u/hoffa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hdbscan\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import adjustText\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.sparse as ss\n",
    "from os.path import isfile\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file\n",
    "from bokeh.models import HoverTool, ColumnDataSource, value, CustomJS\n",
    "from bokeh.models.mappers import LinearColorMapper\n",
    "from bokeh.palettes import plasma\n",
    "from collections import OrderedDict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build SQL Database\n",
    "\n",
    "Since the dataset is huge (71,826,552 comments), we need to read and write to the SQL database in chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(filepath, limit=None, links_only=False):\n",
    "    comments = []\n",
    "    with open(filepath) as fp:\n",
    "        for idx, line in enumerate(fp):\n",
    "            if (limit is not None) and (idx == limit):\n",
    "                break\n",
    "            comment = json.loads(line)\n",
    "            if links_only:\n",
    "                if 'https' in comment['body']:\n",
    "                    comments.append(comment)\n",
    "            else:\n",
    "                comments.append(comment)\n",
    "        return comments\n",
    "    \n",
    "    \n",
    "def extract_subset(filepath, start=0, end=10):\n",
    "    comments = []\n",
    "    with open(filepath) as fp:\n",
    "        for idx, line in enumerate(fp):\n",
    "            if (idx >= start) and (idx < end):\n",
    "                comment = json.loads(line)\n",
    "                comments.append(comment)\n",
    "            elif idx >= end:\n",
    "                break                \n",
    "        return comments\n",
    "    \n",
    "    \n",
    "def write_to_database(db_conn, json_fp, chunk_size):\n",
    "    batch_no=1\n",
    "    for chunk in pd.read_json(json_fp, chunksize=chunk_size, lines=True):\n",
    "        try: \n",
    "            chunk.to_sql('reddit_comments', db_conn, if_exists='append')\n",
    "        except sqlalchemy.exc.SQLAlchemyError as e: \n",
    "            print(\"\\n  {}\".format(e.orig))\n",
    "        print('\\rindex: {}'.format(batch_no), end='')\n",
    "        batch_no+=1\n",
    "        \n",
    "        \n",
    "def create_database(database, n_files, comments_per_file, chunk_size):\n",
    "    for idx in range(0, n_files):\n",
    "        print(\"########## File {} ##########\".format(idx+1))\n",
    "        start = int(idx*comments_per_file)\n",
    "        end = int(start + comments_per_file)\n",
    "        print(\"Extracting comments {} - {}\".format(start, end))\n",
    "        comments = extract_subset(filepath='data/RC_2016-10.json', start=start, end=end)\n",
    "        df = pd.DataFrame(comments)\n",
    "        df.to_json(\"data/RC_2016-10_chunk.json\", orient='records', lines=True)\n",
    "\n",
    "        print(\"Writing to database\")\n",
    "        write_to_database(\n",
    "            db_conn=database, \n",
    "            json_fp=\"data/RC_2016-10_chunk.json\", \n",
    "            chunk_size=chunk_size\n",
    "        )\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_engine('sqlite:///reddit_database_small.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## File 20 ##########\n",
      "Extracting comments 1900000 - 2000000\n",
      "Writing to database\n",
      "index: 100"
     ]
    }
   ],
   "source": [
    "create_database(database=conn, n_files=20, comments_per_file=100000, chunk_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('reddit_database_small.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: check if SUM(1), COUNT(1) assumes zero indexing. Might be the root of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of number of users in each subreddit, and save the result a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY1 = \"\"\"\n",
    "CREATE TABLE subr_users AS\n",
    "    SELECT subreddit, authors, DENSE_RANK() OVER (ORDER BY authors DESC) AS rank_authors\n",
    "    FROM (SELECT subreddit, SUM(1) as authors\n",
    "         FROM (SELECT subreddit, author, COUNT(1) as cnt \n",
    "             FROM reddit_comments\n",
    "             WHERE author NOT LIKE '%bot'\n",
    "             GROUP BY subreddit, author HAVING cnt > 0)\n",
    "         GROUP BY subreddit) t\n",
    "    ORDER BY authors DESC;\n",
    "\"\"\"\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute(QUERY1)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>authors</th>\n",
       "      <th>rank_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>45394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>12063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>11272</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>funny</td>\n",
       "      <td>9622</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFB</td>\n",
       "      <td>9325</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18282</th>\n",
       "      <td>zinesters</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18283</th>\n",
       "      <td>zocken</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18284</th>\n",
       "      <td>zombiemanic</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18285</th>\n",
       "      <td>zoophobiacomic</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18286</th>\n",
       "      <td>zumba</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18287 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit  authors  rank_authors\n",
       "0            AskReddit    45394             1\n",
       "1      leagueoflegends    12063             2\n",
       "2             politics    11272             3\n",
       "3                funny     9622             4\n",
       "4                  CFB     9325             5\n",
       "...                ...      ...           ...\n",
       "18282        zinesters        1           619\n",
       "18283           zocken        1           619\n",
       "18284      zombiemanic        1           619\n",
       "18285   zoophobiacomic        1           619\n",
       "18286            zumba        1           619\n",
       "\n",
       "[18287 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"\"\"SELECT * FROM subr_users\"\"\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new table, we create a list of number of users who authored at least 10 posts in pairs of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY2 = \"\"\"\n",
    "CREATE TABLE overlapping_subr_users AS\n",
    "    SELECT t1.subreddit, t2.subreddit, SUM(1) AS NumOverlaps\n",
    "    FROM (SELECT subreddit, author, COUNT(1) AS cnt \n",
    "         FROM reddit_comments\n",
    "         WHERE author NOT LIKE '%bot'\n",
    "         AND subreddit IN (SELECT subreddit FROM subr_users\n",
    "           WHERE rank_authors>200 AND rank_authors<2201)\n",
    "         GROUP BY subreddit, author HAVING cnt > 10) t1\n",
    "    JOIN (SELECT subreddit, author, COUNT(1) as cnt \n",
    "         FROM reddit_comments\n",
    "         WHERE author NOT LIKE '%bot'\n",
    "         GROUP BY subreddit, author HAVING cnt > 10) t2\n",
    "    ON t1.author=t2.author\n",
    "    WHERE t1.subreddit!=t2.subreddit\n",
    "    GROUP BY t1.subreddit, t2.subreddit\n",
    "\"\"\"\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute(QUERY2)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the result of the second query as a dataframe. Edit the column names and store it for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit:1</th>\n",
       "      <th>NumOverlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>3DS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>3Dprinting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>3dshacks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498500</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>yandere_simulator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498501</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>yokaiwatch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498502</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498503</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>yugioh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498504</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>zen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1498505 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit        subreddit:1  NumOverlaps\n",
       "0            2b2t          2007scape            1\n",
       "1            2b2t       2meirl4meirl            1\n",
       "2            2b2t                3DS            1\n",
       "3            2b2t         3Dprinting            1\n",
       "4            2b2t           3dshacks            1\n",
       "...           ...                ...          ...\n",
       "1498500  zootopia  yandere_simulator            1\n",
       "1498501  zootopia         yokaiwatch            1\n",
       "1498502  zootopia       youtubehaiku            1\n",
       "1498503  zootopia             yugioh            1\n",
       "1498504  zootopia                zen            1\n",
       "\n",
       "[1498505 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\"\"\"SELECT * FROM overlapping_subr_users\"\"\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_subreddit</th>\n",
       "      <th>t2_subreddit</th>\n",
       "      <th>NumOverlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>2007scape</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>3DS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>3Dprinting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b2t</td>\n",
       "      <td>3dshacks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498500</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>yandere_simulator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498501</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>yokaiwatch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498502</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498503</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>yugioh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498504</th>\n",
       "      <td>zootopia</td>\n",
       "      <td>zen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1498505 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        t1_subreddit       t2_subreddit  NumOverlaps\n",
       "0               2b2t          2007scape            1\n",
       "1               2b2t       2meirl4meirl            1\n",
       "2               2b2t                3DS            1\n",
       "3               2b2t         3Dprinting            1\n",
       "4               2b2t           3dshacks            1\n",
       "...              ...                ...          ...\n",
       "1498500     zootopia  yandere_simulator            1\n",
       "1498501     zootopia         yokaiwatch            1\n",
       "1498502     zootopia       youtubehaiku            1\n",
       "1498503     zootopia             yugioh            1\n",
       "1498504     zootopia                zen            1\n",
       "\n",
       "[1498505 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"subreddit\":\"t1_subreddit\", \"subreddit:1\":\"t2_subreddit\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"data/RC_2016-10_subreddit_overlaps_small.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_json(\"data/RC_2016-10_subreddit_overlaps_small.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1498505 entries, 0 to 1498504\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   t1_subreddit  1498505 non-null  object\n",
      " 1   t2_subreddit  1498505 non-null  object\n",
      " 2   NumOverlaps   1498505 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 45.7+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try: rank the subreddits, take out the last few thousand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.sort_values(by=\"NumOverlaps\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.loc[raw_data.NumOverlaps > 2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_subreddit</th>\n",
       "      <th>t2_subreddit</th>\n",
       "      <th>NumOverlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>562154</th>\n",
       "      <td>SVExchange</td>\n",
       "      <td>pokemontrades</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116648</th>\n",
       "      <td>CFBOffTopic</td>\n",
       "      <td>CFB</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132704</th>\n",
       "      <td>Cardinals</td>\n",
       "      <td>Dodgers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211441</th>\n",
       "      <td>Dodgers</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509999</th>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>pokemontrades</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451977</th>\n",
       "      <td>vegasquadrantrp</td>\n",
       "      <td>ProjectFreelancerRP</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83019</th>\n",
       "      <td>BankBallExchange</td>\n",
       "      <td>pokemontrades</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519773</th>\n",
       "      <td>ProjectFreelancerRP</td>\n",
       "      <td>vegasquadrantrp</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210655</th>\n",
       "      <td>ockytop</td>\n",
       "      <td>CFB</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134999</th>\n",
       "      <td>CasualPokemonTrades</td>\n",
       "      <td>pokemontrades</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391161</th>\n",
       "      <td>MLBStreams</td>\n",
       "      <td>CFBStreams</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384508</th>\n",
       "      <td>LonghornNation</td>\n",
       "      <td>CFB</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508972</th>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>CasualPokemonTrades</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198544</th>\n",
       "      <td>nrl</td>\n",
       "      <td>AFL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134318</th>\n",
       "      <td>CasualPokemonTrades</td>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118219</th>\n",
       "      <td>CFBStreams</td>\n",
       "      <td>MLBStreams</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991929</th>\n",
       "      <td>gonewildaudio</td>\n",
       "      <td>GWABackstage</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450690</th>\n",
       "      <td>NYYankees</td>\n",
       "      <td>baseball</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341280</th>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>MLBStreams</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211993</th>\n",
       "      <td>Dodgers</td>\n",
       "      <td>baseball</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561498</th>\n",
       "      <td>SVExchange</td>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509370</th>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>SVExchange</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266187</th>\n",
       "      <td>FloridaGators</td>\n",
       "      <td>CFB</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327573</th>\n",
       "      <td>short</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479660</th>\n",
       "      <td>OpTicGaming</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392243</th>\n",
       "      <td>MLBStreams</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319897</th>\n",
       "      <td>HillaryForPrison</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276946</th>\n",
       "      <td>GWABackstage</td>\n",
       "      <td>gonewildaudio</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755433</th>\n",
       "      <td>bakchodi</td>\n",
       "      <td>IndiaSpeaks</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387588</th>\n",
       "      <td>tall</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287739</th>\n",
       "      <td>redsox</td>\n",
       "      <td>baseball</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304999</th>\n",
       "      <td>sadcringe</td>\n",
       "      <td>CringeAnarchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85018</th>\n",
       "      <td>Battlefield</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995212</th>\n",
       "      <td>gonewildcurvy</td>\n",
       "      <td>gonewild</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179686</th>\n",
       "      <td>netflix</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738801</th>\n",
       "      <td>asoiaf</td>\n",
       "      <td>movies</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119062</th>\n",
       "      <td>CFBStreams</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508614</th>\n",
       "      <td>Pokemonexchange</td>\n",
       "      <td>pokemontrades</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211731</th>\n",
       "      <td>Dodgers</td>\n",
       "      <td>NewYorkMets</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454115</th>\n",
       "      <td>Nationals</td>\n",
       "      <td>CFB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294157</th>\n",
       "      <td>roleplayponies</td>\n",
       "      <td>mylittlepony</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820412</th>\n",
       "      <td>changemyview</td>\n",
       "      <td>politics</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522484</th>\n",
       "      <td>PurplePillDebate</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337758</th>\n",
       "      <td>IndiaSpeaks</td>\n",
       "      <td>bakchodi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952456</th>\n",
       "      <td>fivenightsatfreddys</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464894</th>\n",
       "      <td>NewYorkMets</td>\n",
       "      <td>Dodgers</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133188</th>\n",
       "      <td>Cardinals</td>\n",
       "      <td>baseball</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739103</th>\n",
       "      <td>asoiaf</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119310</th>\n",
       "      <td>CHICubs</td>\n",
       "      <td>CFB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353056</th>\n",
       "      <td>sportsbook</td>\n",
       "      <td>CFB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127195</th>\n",
       "      <td>CampArcadia</td>\n",
       "      <td>CampHalfBloodRP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557727</th>\n",
       "      <td>SFGiants</td>\n",
       "      <td>baseball</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509317</th>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>PokemonPlaza</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507323</th>\n",
       "      <td>PokemonPlaza</td>\n",
       "      <td>Pokemongiveaway</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494514</th>\n",
       "      <td>yugioh</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635138</th>\n",
       "      <td>TickTockManitowoc</td>\n",
       "      <td>SuperMaM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405798</th>\n",
       "      <td>Mariners</td>\n",
       "      <td>CFB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616301</th>\n",
       "      <td>SuperMaM</td>\n",
       "      <td>TickTockManitowoc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127308</th>\n",
       "      <td>CampHalfBloodRP</td>\n",
       "      <td>CampArcadia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393566</th>\n",
       "      <td>techsupport</td>\n",
       "      <td>buildapc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                t1_subreddit         t2_subreddit  NumOverlaps\n",
       "562154            SVExchange        pokemontrades           15\n",
       "116648           CFBOffTopic                  CFB           12\n",
       "132704             Cardinals              Dodgers           10\n",
       "211441               Dodgers            Cardinals           10\n",
       "509999       Pokemongiveaway        pokemontrades            8\n",
       "1451977      vegasquadrantrp  ProjectFreelancerRP            8\n",
       "83019       BankBallExchange        pokemontrades            8\n",
       "519773   ProjectFreelancerRP      vegasquadrantrp            8\n",
       "1210655              ockytop                  CFB            7\n",
       "134999   CasualPokemonTrades        pokemontrades            5\n",
       "391161            MLBStreams           CFBStreams            5\n",
       "384508        LonghornNation                  CFB            5\n",
       "508972       Pokemongiveaway  CasualPokemonTrades            5\n",
       "1198544                  nrl                  AFL            5\n",
       "134318   CasualPokemonTrades      Pokemongiveaway            5\n",
       "118219            CFBStreams           MLBStreams            5\n",
       "991929         gonewildaudio         GWABackstage            4\n",
       "450690             NYYankees             baseball            4\n",
       "1341280        soccerstreams           MLBStreams            4\n",
       "211993               Dodgers             baseball            4\n",
       "561498            SVExchange      Pokemongiveaway            4\n",
       "509370       Pokemongiveaway           SVExchange            4\n",
       "266187         FloridaGators                  CFB            4\n",
       "1327573                short            AskReddit            4\n",
       "479660           OpTicGaming      GlobalOffensive            4\n",
       "392243            MLBStreams        soccerstreams            4\n",
       "319897      HillaryForPrison           The_Donald            4\n",
       "276946          GWABackstage        gonewildaudio            4\n",
       "755433              bakchodi          IndiaSpeaks            3\n",
       "1387588                 tall            AskReddit            3\n",
       "1287739               redsox             baseball            3\n",
       "1304999            sadcringe        CringeAnarchy            3\n",
       "85018            Battlefield        battlefield_4            3\n",
       "995212         gonewildcurvy             gonewild            3\n",
       "1179686              netflix            AskReddit            3\n",
       "738801                asoiaf               movies            3\n",
       "119062            CFBStreams        soccerstreams            3\n",
       "508614       Pokemonexchange        pokemontrades            3\n",
       "211731               Dodgers          NewYorkMets            3\n",
       "454115             Nationals                  CFB            3\n",
       "1294157       roleplayponies         mylittlepony            3\n",
       "820412          changemyview             politics            3\n",
       "522484      PurplePillDebate               AskMen            3\n",
       "337758           IndiaSpeaks             bakchodi            3\n",
       "952456   fivenightsatfreddys            AskReddit            3\n",
       "464894           NewYorkMets              Dodgers            3\n",
       "133188             Cardinals             baseball            3\n",
       "739103                asoiaf            worldnews            3\n",
       "119310               CHICubs                  CFB            3\n",
       "1353056           sportsbook                  CFB            3\n",
       "127195           CampArcadia      CampHalfBloodRP            3\n",
       "557727              SFGiants             baseball            3\n",
       "509317       Pokemongiveaway         PokemonPlaza            3\n",
       "507323          PokemonPlaza      Pokemongiveaway            3\n",
       "1494514               yugioh            AskReddit            3\n",
       "635138     TickTockManitowoc             SuperMaM            3\n",
       "405798              Mariners                  CFB            3\n",
       "616301              SuperMaM    TickTockManitowoc            3\n",
       "127308       CampHalfBloodRP          CampArcadia            3\n",
       "1393566          techsupport             buildapc            3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairwise commenter overlaps: 65\n",
      "t1_subreddit unique subreddits: 53\n",
      "t2_subreddit unique subreddits: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pairwise commenter overlaps: {}\".format(len(raw_data)))\n",
    "print(\"t1_subreddit unique subreddits: {}\".format(len(raw_data[\"t1_subreddit\"].unique())))\n",
    "print(\"t2_subreddit unique subreddits: {}\".format(len(raw_data[\"t2_subreddit\"].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank the subreddits so that they are indexed in order of popularity. Popularity is defined by the total number of unique commenters in each subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use t1_subreddit if it is larger?\n",
    "subreddit_popularity = raw_data.groupby('t2_subreddit')['NumOverlaps'].sum()\n",
    "subreddits = np.array(subreddit_popularity.sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot the data into a matrix such that rows and columns are both indexed by subreddits, and the entry at position (i,j) is the number of overlaps bwteen the ith and jth subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create subreddit-to-integer-index map to convert the subreddit names in the table into numeric row and column indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = dict(np.vstack([subreddits, np.arange(subreddits.shape[0])]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFB 0\n",
      "pokemontrades 1\n",
      "baseball 2\n",
      "AskReddit 3\n",
      "Dodgers 4\n",
      "Pokemongiveaway 5\n",
      "Cardinals 6\n",
      "MLBStreams 7\n",
      "ProjectFreelancerRP 8\n",
      "CFBStreams 9\n",
      "vegasquadrantrp 10\n",
      "soccerstreams 11\n",
      "CasualPokemonTrades 12\n",
      "AFL 13\n",
      "GWABackstage 14\n",
      "The_Donald 15\n",
      "SVExchange 16\n",
      "gonewildaudio 17\n",
      "GlobalOffensive 18\n",
      "CringeAnarchy 19\n",
      "AskMen 20\n",
      "todayilearned 21\n",
      "Battlefield 22\n",
      "roleplayponies 23\n",
      "politics 24\n",
      "CampArcadia 25\n",
      "CampHalfBloodRP 26\n",
      "mylittlepony 27\n",
      "movies 28\n",
      "battlefield_4 29\n",
      "hockey 30\n",
      "bakchodi 31\n",
      "IndiaSpeaks 32\n",
      "NewYorkMets 33\n",
      "PokemonPlaza 34\n",
      "gonewild 35\n",
      "buildapc 36\n",
      "SuperMaM 37\n",
      "TickTockManitowoc 38\n",
      "worldnews 39\n"
     ]
    }
   ],
   "source": [
    "for key, value in index_map.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = raw_data.NumOverlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_indices = raw_data.t2_subreddit.map(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indices = raw_data.t1_subreddit.map(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562154      1\n",
       "116648      0\n",
       "132704      4\n",
       "211441      6\n",
       "509999      1\n",
       "           ..\n",
       "1170080    23\n",
       "1341031     9\n",
       "761862     22\n",
       "814834     30\n",
       "482033     21\n",
       "Name: t2_subreddit, Length: 65, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562154     16.0\n",
       "116648      NaN\n",
       "132704      6.0\n",
       "211441      4.0\n",
       "509999      5.0\n",
       "           ... \n",
       "1170080    27.0\n",
       "1341031    11.0\n",
       "761862     29.0\n",
       "814834      NaN\n",
       "482033      NaN\n",
       "Name: t1_subreddit, Length: 65, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(row_indices[row_indices.isna()==True]))\n",
    "print(len(col_indices[col_indices.isna()==True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sparse matrix. This format requires us to specify triples of row, column, and value for each non-zero entry in the matrix. The COO matrix constructor accepts this as a triple of arrays: the first array is the values, the second and third are arrays of row and column indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative column index found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c1ab57c75c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               raw_data.t1_subreddit.map(index_map))),\n\u001b[1;32m      4\u001b[0m                               \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubreddits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               dtype=np.float64)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml_env/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative row index found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'negative column index found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: negative column index found"
     ]
    }
   ],
   "source": [
    "count_matrix = ss.coo_matrix((raw_data.NumOverlaps, \n",
    "                             (raw_data.t2_subreddit.map(index_map),\n",
    "                              raw_data.t1_subreddit.map(index_map))),\n",
    "                              shape=(subreddits.shape[0], subreddits.shape[0]),\n",
    "                              dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_prob_matrix = count_matrix.tocsr()\n",
    "conditional_prob_matrix = normalize(conditional_prob_matrix, norm='l1', copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting subreddit vectors into a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_vectors = TruncatedSVD(n_components=500, random_state=1).fit_transform(conditional_prob_matrix)\n",
    "reduced_vectors = normalize(reduced_vectors, norm='l2', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(verbose=1, n_components=2, perplexity=50)\n",
    "\n",
    "subreddit_map = tsne.fit_transform(reduced_vectors[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_map_df = pd.DataFrame(subreddit_map, columns=('x', 'y'))\n",
    "subreddit_map_df['subreddit'] = subreddits[:10000]\n",
    "subreddit_map_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_samples=5, min_cluster_size=20).fit(subreddit_map)\n",
    "cluster_ids = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_map_df['cluster'] = cluster_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "# To output to a static html file, comment out the previous\n",
    "# line, and uncomment the line below.\n",
    "# output_file('subreddit_interactive_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a color palette and map clusters to colors\n",
    "palette = ['#777777'] + list(plasma(cluster_ids.max()))\n",
    "\n",
    "colormap = LinearColorMapper(palette=palette, low=-1, high=cluster_ids.max())\n",
    "\n",
    "color_dict = {\n",
    "    'field': 'cluster', \n",
    "    'transform': colormap\n",
    "}\n",
    "\n",
    "# Set fill alpha globally\n",
    "subreddit_map_df['fill_alpha'] = np.exp((subreddit_map.min() - subreddit_map.max()) / 5.0) + 0.05\n",
    "\n",
    "# Build a column data source\n",
    "plot_data = ColumnDataSource(subreddit_map_df)\n",
    "\n",
    "# Custom callback for alpha adjustment\n",
    "jscode=\"\"\"\n",
    "    var data = source.data;\n",
    "    var start = cb_obj.start;\n",
    "    var end = cb_obj.end;\n",
    "    alpha = data['fill_alpha']\n",
    "    for (i = 0; i < alpha.length; i++) {\n",
    "         alpha[i] = Math.exp((start - end) / 5.0) + 0.05;\n",
    "    }\n",
    "    source.trigger('change');\n",
    "\"\"\"\n",
    "\n",
    "# Create the figure and add tools\n",
    "fig = figure(\n",
    "    title='A Map of Subreddits',\n",
    "    plot_width = 900,\n",
    "    plot_height = 900,\n",
    "    tools= ('pan, wheel_zoom, box_zoom,''box_select, reset'),\n",
    "    active_scroll=u'wheel_zoom'\n",
    ")\n",
    "\n",
    "# tools= ('pan, wheel_zoom, box_zoom,''box_select, resize, reset'),\n",
    "fig.add_tools(\n",
    "    HoverTool(\n",
    "        tooltips = OrderedDict(\n",
    "            [('subreddit', '@subreddit'), ('cluster', '@cluster')]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# draw the subreddits as circles on the plot\n",
    "fig.circle(\n",
    "    u'x', u'y', \n",
    "    source = plot_data,\n",
    "    fill_color = color_dict, \n",
    "    line_color = None, \n",
    "    fill_alpha = 'fill_alpha',\n",
    "    size = 10, \n",
    "    hover_line_color = u'black'\n",
    ")\n",
    "\n",
    "callback = CustomJS(\n",
    "    args=dict(\n",
    "        source=plot_data,\n",
    "    ), \n",
    "    code=jscode\n",
    ")\n",
    "\n",
    "# fig.x_range.callback = CustomJS(args=dict(source=plot_data), code=jscode)\n",
    "# fig.y_range.callback = CustomJS(args=dict(source=plot_data), code=jscode)\n",
    "\n",
    "# fig.x_range.js_on_change(\"plot_data\", callback)\n",
    "# fig.y_range.js_on_change(\"plot_data\", callback)\n",
    "\n",
    "# configure visual elements of the plot\n",
    "fig.title.text_font_size = value('18pt')\n",
    "fig.title.align = 'center'\n",
    "fig.xaxis.visible = False\n",
    "fig.yaxis.visible = False\n",
    "fig.grid.grid_line_color = None\n",
    "fig.outline_line_color = '#222222'\n",
    "\n",
    "# # display the figure\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_bounds(dataframe, subreddit):\n",
    "    # Find the cluster the subreddit belongs to\n",
    "    cluster = dataframe.cluster[\n",
    "        dataframe.subreddit == subreddit].values[0]\n",
    "    if cluster == -1:\n",
    "        warn('This subreddit was lost as noise and not in any cluster')\n",
    "        \n",
    "    # Extract the dubset of the dataframe that is the cluster\n",
    "    sub_dataframe = dataframe[dataframe.cluster == cluster]\n",
    "    \n",
    "    x_min = sub_dataframe.x.min()\n",
    "    x_max = sub_dataframe.x.max()\n",
    "    x_padding = (x_max - x_min) * 0.5\n",
    "    x_min -= x_padding\n",
    "    x_max += x_padding\n",
    "    \n",
    "    y_min = sub_dataframe.y.min()\n",
    "    y_max = sub_dataframe.y.max()\n",
    "    y_padding = (y_max - y_min) * 0.5\n",
    "    y_min -= y_padding\n",
    "    y_max += y_padding\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "def data_in_bounds(dataframe, bounds):\n",
    "    return dataframe[\n",
    "        (dataframe.x > bounds[0]) &\n",
    "        (dataframe.x < bounds[1]) &\n",
    "        (dataframe.y > bounds[2]) &\n",
    "        (dataframe.y < bounds[3])\n",
    "    ]\n",
    "\n",
    "\n",
    "def plot_cluster(dataframe, subreddit):\n",
    "    # Build a color map to match the Bokeh plot\n",
    "    colormap = dict(zip(\n",
    "        np.unique(dataframe.cluster),\n",
    "        ['#777777'] + sns.color_palette('plasma', dataframe.cluster.max() + 1).as_hex()\n",
    "    ))\n",
    "    subregion_defined = True\n",
    "    \n",
    "    # Figure and gridspec to layout axes\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    gs = GridSpec(3, 3)\n",
    "    \n",
    "    # First axes, spanning most of the figure\n",
    "    # Contains just the points in a region \n",
    "    # around the points in the cluster\n",
    "    ax1 = plt.subplot(gs[:,:2])\n",
    "    try:\n",
    "        bounds = cluster_bounds(dataframe, subreddit)\n",
    "    except IndexError:\n",
    "        ax1.text(0.5, 0.5, 'Subreddit {} not found!'.format(subreddit), \n",
    "                 horizontalalignment='center', verticalalignment='center',\n",
    "                 transform=ax1.transAxes, fontsize=18)\n",
    "        subregion_defined = False\n",
    "    \n",
    "    if subregion_defined:\n",
    "        to_plot = data_in_bounds(dataframe, bounds)\n",
    "        ax1.scatter(to_plot.x, to_plot.y, c=to_plot.cluster.map(colormap), s=30, alpha=0.5)\n",
    "    \n",
    "        # We want to add text labels. We subsample up to 50 labels\n",
    "        # And then use adjustText to get them non-overlapping\n",
    "        text_elements = []\n",
    "        for row in to_plot.sample(n=min(len(to_plot),50), random_state=0).values:\n",
    "            if row[2] != subreddit:\n",
    "                text_elements.append(ax1.text(row[0], row[1], row[2], alpha=0.5, fontsize=9))\n",
    "        row = to_plot[to_plot.subreddit == subreddit].values[0]\n",
    "        text_elements.append(ax1.text(row[0], row[1], row[2], \n",
    "                                      color='g',\n",
    "                                      alpha=0.5, fontsize=11))\n",
    "        adjustText.adjust_text(text_elements, ax=ax1, lim=100,\n",
    "                               force_text=0.1, force_points=0.1,\n",
    "                               arrowprops=dict(arrowstyle=\"-\", color='k', lw=0.5))\n",
    "    \n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "\n",
    "    # Second axes, center right of the figure\n",
    "    # Plots all the data and a rectangle\n",
    "    # Showing the area selected out\n",
    "    ax2 = plt.subplot(gs[1,2])\n",
    "    ax2.scatter(dataframe.x, dataframe.y, s=20,\n",
    "                c=dataframe.cluster.map(colormap), alpha=0.05)\n",
    "    \n",
    "    if subregion_defined:\n",
    "        ax2.add_patch(Rectangle(xy=(bounds[0], bounds[2]),\n",
    "                                    width=(bounds[1] - bounds[0]),\n",
    "                                    height=(bounds[3] - bounds[2]),\n",
    "                                    edgecolor='k', facecolor='none', lw=1))\n",
    "    ax2.xaxis.set_ticklabels([])\n",
    "    ax2.yaxis.set_ticklabels([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if subregion_defined:\n",
    "        # Now we make use of the power of matplotlib transforms\n",
    "        # to draw line from the subselected rectangle in axes2\n",
    "        # all the way to the bounds of axes1\n",
    "        trans_figure = fig.transFigure.inverted()\n",
    "\n",
    "        ax1_coord = trans_figure.transform(ax1.transAxes.transform((1,0)))\n",
    "        ax2_coord = trans_figure.transform(ax2.transData.transform((bounds[1],bounds[2])))\n",
    "        connector1 = Line2D((ax1_coord[0],ax2_coord[0]),(ax1_coord[1],ax2_coord[1]),\n",
    "                              transform=fig.transFigure, lw=1, color='k')\n",
    "        ax1_coord = trans_figure.transform(ax1.transAxes.transform((1,1)))\n",
    "        ax2_coord = trans_figure.transform(ax2.transData.transform((bounds[1],bounds[3])))\n",
    "        connector2 = Line2D((ax1_coord[0],ax2_coord[0]),(ax1_coord[1],ax2_coord[1]),\n",
    "                              transform=fig.transFigure, lw=1, color='k')\n",
    "\n",
    "        fig.lines = [connector1, connector2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(subreddit_map_df, 'MachineLearning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual, fixed, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(plot_cluster, \n",
    "                dataframe=fixed(subreddit_map_df), \n",
    "                subreddit=Text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_clusters = np.argsort(clusterer.cluster_persistence_)[-10:][::-1]\n",
    "coherence = np.sort(clusterer.cluster_persistence_)[-10:][::-1]\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = plt.gca()\n",
    "ax.bar(np.arange(10), coherence)\n",
    "ax.set_xticks(np.arange(10))\n",
    "ax.set_xticklabels(coherent_clusters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_by_id(dataframe, cluster_id):\n",
    "    subreddits_in_cluster = np.array(dataframe.subreddit[cluster_ids == cluster_id])\n",
    "    plot_cluster(dataframe, subreddits_in_cluster[0])\n",
    "    plt.gcf().text(0.5, 0.98, 'Cluster {}'.format(cluster_id), ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_by_id(subreddit_map_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
